<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Regression and Classification models &#8212; Project Deluge- Predicting Flood Risk November 2024 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=61cd365c" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=686e5160" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=27fed22d" />
    <script src="../_static/documentation_options.js?v=d3eb9a3c"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="regression-and-classification-models">
<h1>Regression and Classification models<a class="headerlink" href="#regression-and-classification-models" title="Link to this heading">¶</a></h1>
<section id="risk-class-prediction-models">
<h2>Risk Class Prediction Models<a class="headerlink" href="#risk-class-prediction-models" title="Link to this heading">¶</a></h2>
<section id="all-zero-risk">
<h3>All Zero Risk<a class="headerlink" href="#all-zero-risk" title="Link to this heading">¶</a></h3>
<p>This model assumes all unlabeled flood risk data is near zero risk (band 1, the modal class), which is the modal class for the data set, which is strongly unbalanced. This is a baseline model to compare against. While it achieve a moderately good accuracy, it is not a useful model for risk prediction, and has little skill.</p>
</section>
<section id="risk-label-prediction-model">
<h3>Risk Label Prediction Model<a class="headerlink" href="#risk-label-prediction-model" title="Link to this heading">¶</a></h3>
<p>The risk label classification task required identifying correlations among attributes to determine their relevance. All attributes, except those predicted in other tasks, were retained for further training. Wide-range features, such as elevation and distance to watercourses, underwent log transformations in the pipeline to standardize their scales.</p>
<p>Given the imbalanced nature of the dataset, particularly for underrepresented risk labels (e.g., labels 6 and 7), oversampling techniques like SMOTE and ADASYN were applied. SMOTE interpolates new samples, while ADASYN focuses on challenging, sparse areas. Class weights were computed to balance the attention paid to all samples, and model parameters, including <cite>eval_metric=’mlogloss’</cite>, were fine-tuned for multi-class classification using XGBoost.</p>
<p>The XGBoost model achieved a higher recall for underrepresented classes and better overall weighted recall compared to Random Forest. This superior performance can be attributed to XGBoost’s ability to capture complex global feature interactions during tree building and its use of the Softmax function for more accurate decision boundaries. In contrast, Random Forest relies on random sampling and majority voting, which are less effective for multi-class tasks. These enhancements made XGBoost the optimal choice for this classification problem.</p>
</section>
</section>
<section id="house-price-prediction-models">
<h2>House Price Prediction Models<a class="headerlink" href="#house-price-prediction-models" title="Link to this heading">¶</a></h2>
<section id="all-england-median">
<h3>All England median<a class="headerlink" href="#all-england-median" title="Link to this heading">¶</a></h3>
<p>This model assumes all unlabeled house price data is the median house price for England. This is a baseline model to compare against. While it achieve a moderately good accuracy, it is not a useful model for risk prediction, and has little skill.</p>
</section>
<section id="median-house-price-prediction-model">
<h3>Median House Price Prediction Model<a class="headerlink" href="#median-house-price-prediction-model" title="Link to this heading">¶</a></h3>
<p>Predicting median house prices proved to be highly challenging, with all tested models performing poorly. The normalized root mean squared error (NRMSE) of 1.427 indicates that the model’s average prediction error surpasses the natural variability of the observed data, reflecting extreme underperformance.</p>
<p>Key issues stem from the dataset’s features, which, while contextually relevant (e.g., elevation and proximity to watercourses), lack general applicability to median price prediction. Additionally, the impact of features such as households and headcounts was minimal or detrimental, likely influenced by factors like London’s Affordable Homes Programme, which altered population dynamics in affluent areas. Despite preprocessing steps like robust scaling, these features failed to enhance the model’s accuracy.</p>
<p>Testing was primarily limited to Random Forest and XGBoost regressors due to computational constraints. XGBoost consistently outperformed Random Forest, as its boosting approach adapts better to low-quality features by refining errors across iterations. In contrast, Random Forest treats all features equally, making it less suitable for this dataset. Key predictors identified through permutation importance—elevation and distance to watercourses—highlight the role of locational attributes in pricing, though their contribution remains insufficient to achieve meaningful accuracy.</p>
<p>Overall, the model’s performance underscores the limitations of the dataset and the inherent difficulty of median house price prediction with the given features. While XGBoost showed marginally better results, significant improvements would require a more robust feature set.</p>
</section>
</section>
<section id="historical-flooding-prediction-model">
<h2>Historical Flooding Prediction Model<a class="headerlink" href="#historical-flooding-prediction-model" title="Link to this heading">¶</a></h2>
<p>For the prediction of historical flooding, we retained all attributes except those designated for prediction in other tasks, as correlation analysis revealed their importance for the target variable, <cite>historicalFlooding</cite>. To address the wide range of values in features such as elevation and distance to watercourses, log transformations were applied during preprocessing.</p>
<p>Given the imbalance in the <cite>historicalFlooding</cite> dataset, oversampling techniques were employed to enhance recall and F1-score. Both SMOTE and SMOTEENN were tested, with SMOTE yielding superior results by generating synthetic samples without excessive noise removal. Random Forest, combined with SMOTE, achieved the highest performance, improving recall and F1-score by 2% over XGBoost. The model’s success is attributed to its balanced treatment of feature values. However, Random Forest incurred higher computational costs compared to XGBoost, which benefits from efficient parallel processing and limited tree depth. Ultimately, Random Forest with SMOTE was selected for its superior experimental performance.</p>
</section>
<section id="predicting-local-authority">
<h2>Predicting Local Authority<a class="headerlink" href="#predicting-local-authority" title="Link to this heading">¶</a></h2>
<p>For predicting local authorities, we used <strong>Random Forest</strong> and <strong>XGBoost</strong> for their scalability and efficiency with large datasets. Other models like KNN and SVM were excluded due to higher computational costs and inefficiencies with large-scale data.</p>
<section id="methodology">
<h3>Methodology<a class="headerlink" href="#methodology" title="Link to this heading">¶</a></h3>
<ol class="arabic simple">
<li><p><strong>Classification</strong>:
- Metrics: <cite>mlogloss</cite> (calibrates probabilities) and <cite>merror</cite> (tracks misclassifications).
- XGBoost outperformed Random Forest due to better handling of complex class boundaries and imbalanced data.</p></li>
<li><p><strong>Regression</strong>:
- Techniques: <strong>SMOTE</strong> and <strong>ADASYN</strong> were applied to balance training data.
- Metrics: <strong>RMSE</strong> and <strong>R²</strong> for model evaluation.</p></li>
</ol>
<p>XGBoost consistently showed better accuracy and model fit, making it the preferred choice for both classification and regression tasks.</p>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">Project Deluge- Predicting Flood Risk</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2024, Miles Weberman, Julia Metz, David Mamane, Precious Okon, Yixuan Yan, Haoran Sun, Pengjie Wang, Yiyu Yang.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.1.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
      |
      <a href="../_sources/docs/models.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>